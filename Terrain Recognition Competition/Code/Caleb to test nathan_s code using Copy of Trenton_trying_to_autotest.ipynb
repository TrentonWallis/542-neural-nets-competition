{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Caleb to test nathan's code using Copy of Trenton_trying_to_autotest.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"J-_wQPlIxomJ"},"outputs":[],"source":["\n","# necessary imports\n","import numpy as np\n","import csv\n","import os\n","from google.colab import drive \n","import matplotlib.pyplot as plt\n","import random # Added by Caleb\n","import math # Added by Caleb\n","import os\n","import torch\n","import pandas as pd\n","from torchvision.io import read_image\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n"]},{"cell_type":"code","source":["from google.colab import drive \n","drive.mount('/content/drive/') ## mount to drive. This will ask for permission to access your Google drive each time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3c_WuMrOzN7T","executionInfo":{"status":"ok","timestamp":1649790543185,"user_tz":240,"elapsed":25406,"user":{"displayName":"Nathan Kohen","userId":"04529003586658249277"}},"outputId":"35181c0d-cf98-4ae6-8fae-23a89bdc17ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["data_folder_path = \"/content/drive/Shareddrives/Neural Nets/Competition/ECE542_sp2022_Project_TerrainRecognition/\" # path into Lobton's directory \n","type_of_data = \"TrainingData\" # Read in the type of data you want. Options are either:  'TrainingData' or 'TestData'\n","list_of_files = os.listdir(data_folder_path + type_of_data) # List everything in the directory at place 2022_Project_TerrainRecognition/TrainingData or /TestData (from line above)\n","list_of_files.sort() # Sort the list of files\n","print(list_of_files) # Print out the list of files\n","# need to load all this data in for augmentation (only the x data, but need to match what y data it connects with)\n","# we need to figure out what data we want to use too. "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJJ9EhzAzOQU","executionInfo":{"status":"ok","timestamp":1649790546882,"user_tz":240,"elapsed":3702,"user":{"displayName":"Nathan Kohen","userId":"04529003586658249277"}},"outputId":"d639727d-0246-42c2-f28d-f16989c33524"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['subject_001_01__x.csv', 'subject_001_01__x_time.csv', 'subject_001_01__y.csv', 'subject_001_01__y_time.csv', 'subject_001_02__x.csv', 'subject_001_02__x_time.csv', 'subject_001_02__y.csv', 'subject_001_02__y_time.csv', 'subject_001_03__x.csv', 'subject_001_03__x_time.csv', 'subject_001_03__y.csv', 'subject_001_03__y_time.csv', 'subject_001_04__x.csv', 'subject_001_04__x_time.csv', 'subject_001_04__y.csv', 'subject_001_04__y_time.csv', 'subject_001_05__x.csv', 'subject_001_05__x_time.csv', 'subject_001_05__y.csv', 'subject_001_05__y_time.csv', 'subject_001_06__x.csv', 'subject_001_06__x_time.csv', 'subject_001_06__y.csv', 'subject_001_06__y_time.csv', 'subject_001_07__x.csv', 'subject_001_07__x_time.csv', 'subject_001_07__y.csv', 'subject_001_07__y_time.csv', 'subject_001_08__x.csv', 'subject_001_08__x_time.csv', 'subject_001_08__y.csv', 'subject_001_08__y_time.csv', 'subject_002_01__x.csv', 'subject_002_01__x_time.csv', 'subject_002_01__y.csv', 'subject_002_01__y_time.csv', 'subject_002_02__x.csv', 'subject_002_02__x_time.csv', 'subject_002_02__y.csv', 'subject_002_02__y_time.csv', 'subject_002_03__x.csv', 'subject_002_03__x_time.csv', 'subject_002_03__y.csv', 'subject_002_03__y_time.csv', 'subject_002_04__x.csv', 'subject_002_04__x_time.csv', 'subject_002_04__y.csv', 'subject_002_04__y_time.csv', 'subject_002_05__x.csv', 'subject_002_05__x_time.csv', 'subject_002_05__y.csv', 'subject_002_05__y_time.csv', 'subject_003_01__x.csv', 'subject_003_01__x_time.csv', 'subject_003_01__y.csv', 'subject_003_01__y_time.csv', 'subject_003_02__x.csv', 'subject_003_02__x_time.csv', 'subject_003_02__y.csv', 'subject_003_02__y_time.csv', 'subject_003_03__x.csv', 'subject_003_03__x_time.csv', 'subject_003_03__y.csv', 'subject_003_03__y_time.csv', 'subject_004_01__x.csv', 'subject_004_01__x_time.csv', 'subject_004_01__y.csv', 'subject_004_01__y_time.csv', 'subject_004_02__x.csv', 'subject_004_02__x_time.csv', 'subject_004_02__y.csv', 'subject_004_02__y_time.csv', 'subject_005_01__x.csv', 'subject_005_01__x_time.csv', 'subject_005_01__y.csv', 'subject_005_01__y_time.csv', 'subject_005_02__x.csv', 'subject_005_02__x_time.csv', 'subject_005_02__y.csv', 'subject_005_02__y_time.csv', 'subject_005_03__x.csv', 'subject_005_03__x_time.csv', 'subject_005_03__y.csv', 'subject_005_03__y_time.csv', 'subject_006_01__x.csv', 'subject_006_01__x_time.csv', 'subject_006_01__y.csv', 'subject_006_01__y_time.csv', 'subject_006_02__x.csv', 'subject_006_02__x_time.csv', 'subject_006_02__y.csv', 'subject_006_02__y_time.csv', 'subject_006_03__x.csv', 'subject_006_03__x_time.csv', 'subject_006_03__y.csv', 'subject_006_03__y_time.csv', 'subject_007_01__x.csv', 'subject_007_01__x_time.csv', 'subject_007_01__y.csv', 'subject_007_01__y_time.csv', 'subject_007_02__x.csv', 'subject_007_02__x_time.csv', 'subject_007_02__y.csv', 'subject_007_02__y_time.csv', 'subject_007_03__x.csv', 'subject_007_03__x_time.csv', 'subject_007_03__y.csv', 'subject_007_03__y_time.csv', 'subject_007_04__x.csv', 'subject_007_04__x_time.csv', 'subject_007_04__y.csv', 'subject_007_04__y_time.csv', 'subject_008_01__x.csv', 'subject_008_01__x_time.csv', 'subject_008_01__y.csv', 'subject_008_01__y_time.csv']\n"]}]},{"cell_type":"code","source":["class CustomImageDataset(Dataset):\n","    def __init__(self, x_data, y_data, img_dir=None, transform=None, target_transform=None):\n","        self.img_labels = y_data\n","        self.img_dir = img_dir\n","        self.x_data = x_data\n","        self.y_data = y_data\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        image = self.x_data[idx]\n","        label = self.y_data[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label\n"],"metadata":{"id":"uZjKtqu5Vv-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code block created by Caleb\n","# Goal: Session class that holds subject and session number, and also returns the data for that session\n","\n","# This class can return the name of the file that holds the requested data\n","    # Example of how to use:\n","    # newSession = Session(4, 5)\n","    # newStr = newSession.xTimeName()\n","    # print(newStr)\n","    # # Prints out \"subject_004_05__x.csv\"\n","\n","class Session:\n","  def __init__(self, subject_number, session_number):\n","    self.subject_number = int(subject_number)  # Initialize subject number\n","    self.session_number = int(session_number)  # Initialize session number\n","\n","  # Each of the following member functions return the name of the specified file for that subject and session number of the Session:\n","\n","  def xTimeName(self):\n","    return \"subject_\" + f\"{self.subject_number:03d}\" + \"_\" + f\"{self.session_number:02d}\" + \"__x_time.csv\"\n","\n","  def yTimeName(self):\n","    return \"subject_\" + f\"{self.subject_number:03d}\" + \"_\" + f\"{self.session_number:02d}\" + \"__y_time.csv\"\n","\n","  def xDataName(self):\n","    return \"subject_\" + f\"{self.subject_number:03d}\" + \"_\" + f\"{self.session_number:02d}\" + \"__x.csv\"\n","\n","  def yDataName(self):\n","    return \"subject_\" + f\"{self.subject_number:03d}\" + \"_\" + f\"{self.session_number:02d}\" + \"__y.csv\"\n","\n","\n","  # This function input is the Session object that contians the subject and session numbers\n","  def getXDataFromFile(self):\n","    x_data_path = data_folder_path + \"TrainingData/\" + self.xDataName() # Get the path to the x_data file \n","    x_data = np.genfromtxt(x_data_path, delimiter=',')  # Read the data in from the text file\n","    return x_data  # Return the data array\n","    # This function returns the array of all the six x values\n","\n","  def getXTimeFromFile(self):\n","    x_time_path = data_folder_path + \"TrainingData/\" + self.xTimeName() # Get the path to the x_data file \n","    x_time = np.genfromtxt(x_time_path, delimiter=',')  # Read the data in from the text file\n","    return x_time  # Return the data array\n","    # This function returns the array of just the x time values\n","\n","  def getYTimeFromFile(self):\n","    y_time_path = data_folder_path + \"TrainingData/\" + self.yTimeName() # Get the path to the x_data file \n","    y_time = np.genfromtxt(y_time_path, delimiter=',')  # Read the data in from the text file\n","    return y_time  # Return the data array\n","    # This function returns the array of just the y time values\n","\n","\n"],"metadata":{"id":"9rupYvJ8zg7D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code block created by Caleb:\n","# Goal is to create list of each session, with a unique session id (session id made up of subject number and session number)\n","\n","list_of_sessions = []\n","\n","for file_name in list_of_files:\n","  # Extract subject and session number from file_name:\n","  new_subject_number = int(file_name[8:11]) # Since all provided subject and session numbers are single digit, we can \n","  new_session_number = int(file_name[12:14]) #   pick them out of the file name by grabbing an exact character number.\n","  \n","\n","\n","  # Check if I should add this session to the list of sessions\n","  should_add_session = True # Create a variable that by default should add the session\n","  for session in list_of_sessions: # Loop through the sessions in the list of sessions (list I may need to add it to)\n","    comp_subject_number = session.subject_number # Get both new session and subject number\n","    comp_session_number = session.session_number #   save them as comp_\n","    if (comp_session_number == new_session_number) and (comp_subject_number == new_subject_number): # If comp session and subject are equal to new subject and session\n","      should_add_session = False # In this case, that would mean that I should /not/ add the new session\n","\n","  if should_add_session: # If I should add the session\n","    newSession = Session(new_subject_number, new_session_number) # Initialize the new session object with the new subject and session values\n","    list_of_sessions.append(newSession) # Append the new session to the list of sessions\n","\n","# Now list_of_sessions has a list of Session objects for each of the sessions\n","\n","# Print out the list of the sessions in list_of_sessions:\n","# for session in list_of_sessions:\n","#   newStr = \"Subject: \" + str(session.subject_number) + \". Session: \" + str(session.session_number)\n","#   print(newStr) \n"],"metadata":{"id":"0nsD3egZzhsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code block created by Caleb\n","# Goal: Create a function that will take in an array of size [(length of file) x 6] and pad it with zeros for image size\n","\n","# This function pads with image width - 1 rows of zeros\n","def padData(data, image_width):\n","  dim = [image_width - 1,6] # The dimensions of the zeros will be the width of the image and six wide\n","  zeroArray = np.zeros(dim) # Create an array with zeros at the beginning of the correct size\n","  return np.concatenate((zeroArray, data)) # Concatonate the two arrays together with the zeros at the beginning\n","\n","# Print out the data for a small data array to see where the zeros go\n","data = np.array([[1, 2, 3, 4, 5, 6], [3, 4, 5, 6, 7, 5]])\n","paddedData = padData(data, 3) \n","print(data)"],"metadata":{"id":"KUAJ9FFgy2le","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649790547386,"user_tz":240,"elapsed":9,"user":{"displayName":"Nathan Kohen","userId":"04529003586658249277"}},"outputId":"bfa5a3be-c9f9-4c36-b071-0a65bbf17b11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2 3 4 5 6]\n"," [3 4 5 6 7 5]]\n"]}]},{"cell_type":"code","source":["# Code block created by Caleb\n","# Goal: Step three of the whiteboard photo, so create \"images\" from padded data\n","\n","# This function takes in the padded data (an array  [(image_width + 40*session lenght).x 6] ) and an integer of the width of an image\n","def createImages(paddedData, image_width):\n","  all_images = [] # Create an empty array that will eventually hold all the images for this session's data\n","  number_of_images = paddedData.shape[0] - image_width + 1  # The number of images I should create is padded_data - (image_width - 1)\n","  for i in range(number_of_images): # Loop through i for each of the images I need to create\n","    all_images.append(paddedData[i:(i+image_width)])  # Grab out the array from the padded data equal to the image_width and starting at i, and append it to all images\n","  return np.asarray(all_images) \n","\n","\n","# This example uses the 'data' array from the code block above to pass into this function to see if it successfully creates two images\n","#   One should have two rows of zeros (because it gets all the padding) and the next should have one row of zeros\n","images = createImages(paddedData, 3)\n","print(images)"],"metadata":{"id":"TD-14JARy7g1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649790547386,"user_tz":240,"elapsed":7,"user":{"displayName":"Nathan Kohen","userId":"04529003586658249277"}},"outputId":"43e7c708-d637-4865-c624-6b40aa4cd19e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0.]\n","  [1. 2. 3. 4. 5. 6.]]\n","\n"," [[0. 0. 0. 0. 0. 0.]\n","  [1. 2. 3. 4. 5. 6.]\n","  [3. 4. 5. 6. 7. 5.]]]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"HIglJIso0iTR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# I will use the first session for this example:\n","example_session = list_of_sessions[0]\n","\n","example_x_data = example_session.getXDataFromFile()\n","example_x_time = example_session.getXTimeFromFile()\n","#example_y_data = example_session.getYDataFromFile() # y data does not exist here\n","example_y_time = example_session.getYTimeFromFile()\n","\n","# No need to extrapolate the ys \n","#xample_extrapolated_y = extrapolatedYs(example_x_time, example_y_time, example_y_data)\n","\n","# Now the x data and the extrapolate_y have the correct sizes, so y is the predictions we want\n","print(\"New y size, and then x data shape\")\n","\n","print(example_x_data.shape)\n","print(\"- - -\")\n","\n","# Now I will show the examples of transforming the x values into images. \n","example_image_width = 60 # You can play around with the width of the image\n","example_x_padded = padData(example_x_data, example_image_width)\n","print(\"With padding:\")\n","print(example_x_padded.shape)\n","print(\"- - -\")\n","\n","example_x_images = createImages(example_x_padded, example_image_width)\n","print(\"Shape of images, so should be back down to number of x values, with image_size x 6 secondary dimensions\")\n","print(example_x_images.shape)\n","print(\"- - -\")\n","print(\"Printing first images\")\n","# print(example_x_images[0])\n","# print(example_x_images[1])\n","\n","# So the data we're treating just like images for classification are:\n","# example_x_images          as the images\n","# example_extrapolated_y    as the labels"],"metadata":{"id":"_PUNpbVOz7TI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649790550376,"user_tz":240,"elapsed":2994,"user":{"displayName":"Nathan Kohen","userId":"04529003586658249277"}},"outputId":"8080fd11-815a-4fac-ba62-0bb62da00336"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["New y size, and then x data shape\n","(37890, 6)\n","- - -\n","With padding:\n","(37949, 6)\n","- - -\n","Shape of images, so should be back down to number of x values, with image_size x 6 secondary dimensions\n","(37890, 60, 6)\n","- - -\n","Printing first images\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"jSf_V3gL0fys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Code block created by Caleb\n","\n","def getImagesFromSession(session, image_width):\n","  image_width_number = int(image_width * 40) # This is the conversion rate between image_width in seconds and image_width the number of samples in an image\n","\n","  x_data = session.getXDataFromFile() # Get all the data for that session\n","  x_time = session.getXTimeFromFile()\n","  y_time = session.getYTimeFromFile()\n","\n","  \n","  x_padded = padData(x_data, image_width_number) # Pad the x values\n","  x_images = createImages(x_padded, image_width_number) # Then create images\n","\n","\n","\n","  print(\"Done processing session!\")\n","\n","\n","  return np.array(x_time), np.asarray(x_images), np.asarray(y_time)\n","\n","#Yt_train = Yt_train.type(torch.LongTensor)\n","# This next line calls the function to get the data for the model with the parameters passed in.\n","# Remember that image width and set length are in seconds\n","\n"],"metadata":{"id":"yLtJnh3O0OSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["our_transform = transforms.Compose([\n","    # Converting RGB [0,255] to Tensor [0,1]\n","    transforms.ToTensor(),\n","    ])\n","\n","# def getYLabels(session, image_width, model):\n","#   x_time, x_images, y_time = getImagesFromSession(session, image_width)\n","#   model.eval()\n","#   test_data = CustomImageDataset(x_images, x_time, transform=our_transform) # x_time is just filler here \n","#   test_loader = torch.utils.data.DataLoader(test_data, batch_size=len(x_images))\n","#   _iter = iter(test_loader)\n","#   print(type(_iter))\n","#   data, index = next(_iter)\n","#   print(data.shape)\n","#   print(type(data))\n","#   predictions = model(data)\n","#   return x_time, x_images, y_time, predictions\n","\n","\n","\n","\n","\n","def getYLabels(session, image_width, model): #TODO: Could there be a bug here? So our model is good but we arent spitting things out in the righ place?????\n","  x_time, x_images, y_time = getImagesFromSession(session, image_width)\n","  #print(\"X_Images Shape:\", x_images.shape)\n","  predictions = []\n","\n","  model.eval()\n","  test_data = CustomImageDataset(x_images, x_time, transform=our_transform) # x_time is just filler here \n","  test_loader = torch.utils.data.DataLoader(test_data, batch_size=20)\n","  for data, _target in test_loader:\n","  \n","    output = model(data)\n","    output_numpy =  output.detach().numpy()\n","    for out in output_numpy:\n","      predictions.append(out)\n","\n","  return x_time, x_images, y_time, np.asarray(predictions)\n","\n","\n","  "],"metadata":{"id":"T4fLQZcaQV1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def loadModelStateFromFile(model, filename):\n","  ''' Load model's state onto model passed in from a model file'''\n","  competition_path = \"/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Models/\" #path to data folder in drive\n","  model_file_path = os.path.join(competition_path, filename+\".pt\")  #joing path and adding .npy to filename passed in\n","  print(model_file_path)\n","  model.load_state_dict(torch.load(model_file_path)) # Should not need a return since the model will be modified through its object \n"],"metadata":{"id":"QDV-y2u_S_9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Custom CNN\n","# Defining the CNN architecture\n","#Trenton's Net class\n","# class Net(nn.Module):\n","#   def __init__(self):\n","#     super(Net, self).__init__()\n","#     self.conv1 = nn.Conv2d(1, 6, 5, padding=2, padding_mode='zeros', dtype=float)\n","#    ## nn.MaxPool2d()\n","#     self.conv2 = nn.Conv2d(6, 16, 5, dtype=float)\n","#     self.fc1 = nn.Linear(16 * 56 * 2, 800, dtype=float)\n","#     self.fc2 = nn.Linear(800, 200, dtype=float) \n","#     self.fc3 = nn.Linear(200, 50, dtype=float)\n","#     self.fc4 = nn.Linear(50, 4, dtype=float)\n","#   def forward(self, x):\n","#     x = F.relu(self.conv1(x))\n","#     x = F.relu(self.conv2(x))\n","#     x = x.view(-1, 16 * 56 * 2) # At this point the feature map is 5 x 5 x 16\n","#     x = F.relu(self.fc1(x))\n","#     x = F.relu(self.fc2(x))\n","#     x = F.relu(self.fc3(x))\n","#     x = self.fc4(x)\n","#     return x\n","class Net(nn.Module):\n","  def __init__(self, ):\n","    super(Net, self).__init__()\n","    self.conv1 = nn.Conv2d(1, 128, (6,30), dtype=float)\n","    self.drop2 = nn.Dropout2d(0.5)\n","    self.drop1 = nn.Dropout(0.2)\n","    self.maxPool = nn.MaxPool1d(31, 1)\n","    # self.batchNorm1 = nn.BatchNorm2d(128, dtype = float)\n","    # self.batchNorm2 = nn.BatchNorm2d(16, dtype = float)\n","    # self.batchNorm3 = nn.BatchNorm1d(800, dtype = float)\n","    # self.batchNorm4 = nn.BatchNorm1d(200, dtype = float)\n","    # self.batchNorm5 = nn.BatchNorm1d(50, dtype = float)\n","    self.fc1 = nn.Linear(128 * 31 * 1, 128, dtype=float)\n","    self.fc2 = nn.Linear(128, 64, dtype=float) \n","    self.fc3 = nn.Linear(64, 32, dtype=float)\n","    self.fc4 = nn.Linear(32, 4, dtype=float)\n","  def forward(self, x):\n","    x = self.drop2(F.relu(self.conv1(x)))\n","    # x = x.view(-1, 128 * 30 * 6) \n","    x = x.view(-1, 128 * 31 * 1) \n","    # x= self.maxPool(x)\n","    x = self.drop1(F.relu(self.fc1(x)))\n","    x = self.drop1(F.relu(self.fc2(x)))\n","    x = F.relu(self.fc3(x))\n","    x = self.fc4(x)\n","    return x\n","\n","\n","# class Net(nn.Module):\n","#   def __init__(self, ):\n","#     super(Net, self).__init__()\n","#     self.conv1 = nn.Conv2d(1, 4, 5, padding=2, padding_mode='zeros', dtype=float)\n","#    ## nn.MaxPool2d()\n","#     self.conv2 = nn.Conv2d(4, 8, 5, padding=2, padding_mode='zeros', dtype=float)\n","#     self.drop2 = nn.Dropout2d(0.1)\n","#     self.drop1 = nn.Dropout(0.1)\n","#     self.batchNorm1 = nn.BatchNorm2d(4, dtype = float)\n","#     self.batchNorm2 = nn.BatchNorm2d(8, dtype = float)\n","#     self.batchNorm3 = nn.BatchNorm1d(512, dtype = float)\n","#     self.batchNorm4 = nn.BatchNorm1d(128, dtype = float)\n","#     self.batchNorm5 = nn.BatchNorm1d(32, dtype = float)\n","#     self.fc1 = nn.Linear(8 * 40 * 6, 512, dtype=float)\n","#     self.fc2 = nn.Linear(512, 128, dtype=float) \n","#     self.fc3 = nn.Linear(128, 32, dtype=float)\n","#     self.fc4 = nn.Linear(32, 4, dtype=float)\n","#   def forward(self, x):\n","#     x = self.drop2(F.relu(self.batchNorm1(self.conv1(x))))\n","#     x = self.drop2(F.relu(self.batchNorm2(self.conv2(x))))\n","#     x = x.view(-1, 8 * 40 * 6) # At this point the feature map is 5 x 5 x 16\n","#     x = self.drop1(F.relu(self.batchNorm3(self.fc1(x))))\n","#     x = self.drop1(F.relu(self.batchNorm4(self.fc2(x))))\n","#     x = self.drop1(F.relu(self.batchNorm5(self.fc3(x))))\n","#     x = self.fc4(x)\n","#     return x\n","\n","# Nathan/Caleb's Randomization Working Net:\n","# Defining the CNN architecture\n","# class Net(nn.Module):\n","#   def __init__(self, ):\n","#     super(Net, self).__init__()\n","#     self.conv1 = nn.Conv2d(1, 6, 5, padding=2, padding_mode='zeros', dtype=float)\n","#    ## nn.MaxPool2d()\n","#     self.conv2 = nn.Conv2d(6, 16, 5, padding=2, padding_mode='zeros', dtype=float)\n","#     self.drop2 = nn.Dropout2d(0.1)\n","#     self.drop1 = nn.Dropout(0.1)\n","#     self.batchNorm1 = nn.BatchNorm2d(6, dtype = float)\n","#     self.batchNorm2 = nn.BatchNorm2d(16, dtype = float)\n","#     self.batchNorm3 = nn.BatchNorm1d(800, dtype = float)\n","#     self.batchNorm4 = nn.BatchNorm1d(200, dtype = float)\n","#     self.batchNorm5 = nn.BatchNorm1d(50, dtype = float)\n","#     self.fc1 = nn.Linear(16 * 60 * 6, 800, dtype=float)\n","#     self.fc2 = nn.Linear(800, 200, dtype=float) \n","#     self.fc3 = nn.Linear(200, 50, dtype=float)\n","#     self.fc4 = nn.Linear(50, 4, dtype=float)\n","#   def forward(self, x):\n","#     x = self.drop2(F.relu(self.batchNorm1(self.conv1(x))))\n","#     x = self.drop2(F.relu(self.batchNorm2(self.conv2(x))))\n","#     x = x.view(-1, 16 * 60 * 6) # At this point the feature map is 5 x 5 x 16\n","#     x = self.drop1(F.relu(self.batchNorm3(self.fc1(x))))\n","#     x = self.drop1(F.relu(self.batchNorm4(self.fc2(x))))\n","#     x = self.drop1(F.relu(self.batchNorm5(self.fc3(x))))\n","#     x = self.fc4(x)\n","#     return x\n"],"metadata":{"id":"Ay5vxZP3S0G-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_session = list_of_sessions[0]\n","# test_model = Net()\n","\n","# loadModelStateFromFile(test_model, \"Test_Model\")\n","# test_x_time, test_x_data, test_y_time, test_predictions = getYLabels(test_session, 1.5, test_model)\n"],"metadata":{"id":"HTlguJmNSLRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(test_predictions)\n","\n","# print(test_predictions[0])\n","\n","\n","# print(test_predictions[100][0])\n","# print(test_predictions[100][1])\n","# print(test_predictions[100][2])\n","# print(test_predictions[100][3])\n"],"metadata":{"id":"oJfSb-07k02L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# # for test_pred in test_predictions:\n","# #   print(test_pred.shape)\n","# _, max_indexes = torch.max(test_predictions, 1)\n","# #max_indexes.append(max_index)\n","\n","\n","\n","\n"],"metadata":{"id":"1mKIVf3X1H0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(max_indexes[1000])\n","\n","# # for index in max_indexes:\n","# #   print(int(index))\n","# y_lined_up_with_x = []\n","# for index in max_indexes:\n","#   y_lined_up_with_x.append(int(index))\n","\n","# y_lined_up_with_x = np.asarray(y_lined_up_with_x)"],"metadata":{"id":"xT4qRwWf2gaJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \"Downsample\" Y labels to correpond to what needs to be submitted\n","def deExtrapolateYs(x_time, y_time, y_lined_up_with_x):\n","  correctY = [] #Empty list for the newly transformed y values\n","  x_time_array = np.asarray(x_time)\n","  for y_t in y_time: # Loop over every y_time value\n","    index = (np.abs(x_time_array - y_t)).argmin() # Get index of closeset x_time to the y_t you are currently looking for\n","    correctY.append(y_lined_up_with_x[index]) # Add the y value at that index to the transformed y's\n","  return np.asarray(correctY)\n"],"metadata":{"id":"F_YFV96NT5K7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# actual_ys = deExtrapolateYs(test_x_time, test_y_time, y_lined_up_with_x)"],"metadata":{"id":"19X5WI0i3AQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(actual_ys.shape)"],"metadata":{"id":"25P0HUBq3fs5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(actual_ys[0])"],"metadata":{"id":"wxsdfQp03rjl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pd.DataFrame(actual_ys).to_csv('first_y_perhaps')"],"metadata":{"id":"965soREA3yOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# np.savetxt('/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Caleb Playing with It/first_y_save_txt', actual_ys)"],"metadata":{"id":"N48xa_vj4Z1U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pd.DataFrame(actual_ys).to_csv('/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Caleb Playing with It/first_y_maybe')"],"metadata":{"id":"yHTuxMwn5sEs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# actual_ys.tofile('/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Caleb Playing with It/first_y_maybe', sep='\\n')"],"metadata":{"id":"Ij7MCl5R5v1o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_Y_values_from_session(session):\n","  # basicaly just getting data as numpy array \n","  # need to make sure y_session data even exits, may be on session without data\n","  y_data_path = data_folder_path + \"TrainingData/\" + \"subject_\" + f\"{session.subject_number:03d}\" + \"_\" + f\"{session.session_number:02d}\" + \"__y.csv\" # Get the path to the x_data file \n","  try:  \n","    y_data = np.genfromtxt(y_data_path, delimiter=',')  # Read the data in from the text file\n","  except:\n","    print(y_data_path, \" was NOT FOUND\")\n","    return None # returns none so we cna exit\n","  return y_data  # Return the data array\n","  "],"metadata":{"id":"ElP6S4VzcR1h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extrapolatedYs(x_time, y_time, y):\n","  transformedY = [] #Empty list for the newly transformed y values\n","  y_time_array = np.asarray(y_time) # Create the y_time values as an array\n","  for x_t in x_time: # Loop over every x_time value\n","    index = (np.abs(y_time_array - x_t)).argmin() # I found this online to get the index of the closest value from the y_time arrays\n","    transformedY.append(y[index]) # Add the y value at that index to the transformed y's\n","  return np.asarray(transformedY)"],"metadata":{"id":"73BXQaIqTaXR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" from sklearn.metrics import precision_recall_fscore_support \n"," classes = [0, 1, 2, 3]\n","\n","def get_session_accuracy_and_f1_score(indv_session, predcitions_y_values):\n","  session_true_y_values = get_Y_values_from_session(indv_session)\n","  session_upsampled_y_values = extrapolatedYs(session.getXTimeFromFile(), session.getYTimeFromFile(),  session_true_y_values)\n","  temp_precision_all, temp_recall_all, temp_fscore_all, _ = precision_recall_fscore_support(session_upsampled_y_values, predcitions_y_values, average=\"macro\", labels=classes, zero_division=0, beta=1) \n","  amount_correct = np.sum(predcitions_y_values == session_upsampled_y_values)\n","\n","  # get amount of each number \n","  amount_per_class = [0, 0, 0, 0]\n","  amount_guessed_correct_per_class = [0, 0, 0, 0]\n","  amount_guessed_per_class = [0, 0, 0 ,0]\n","  accuracy_per_class = [0, 0, 0, 0]\n","  guessed_vs_real_ratio = [0, 0, 0, 0]\n","\n","  \n","  for index, true_value in enumerate(session_upsampled_y_values):\n","    amount_per_class[int(true_value)] +=1\n","    if(true_value == predcitions_y_values[index]):\n","      amount_guessed_correct_per_class[int(true_value)] += 1\n","  \n","  for label in classes:\n","    accuracy_per_class[label] = amount_guessed_correct_per_class[label]/amount_per_class[label] # getting accuracy \n","    amount_guessed_per_class[label] = np.sum(predcitions_y_values == label)\n","    guessed_vs_real_ratio[label] = amount_guessed_per_class[label]/ amount_per_class[label]\n","\n","\n","\n","  accuracy = amount_correct/session_upsampled_y_values.shape[0]\n","  return accuracy, temp_fscore_all, accuracy_per_class, guessed_vs_real_ratio\n"],"metadata":{"id":"hk5EmRaLfspO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Net()\n","loadModelStateFromFile(model, \"nathan_final_model\") # \"Test_Model\" for bad 77% model\n","\n","one_session = []\n","one_session.append(list_of_sessions[1])\n","\n","for session in list_of_sessions:\n","  x_time, x_data, y_time, predictions = getYLabels(session, 1.5, model) # This is 1.5 for bad 77% model\n","  predictions = torch.from_numpy(predictions)\n","  \n","  y_lined_up_with_x = []\n","  for index in max_indexes:\n","    y_lined_up_with_x.append(int(index))\n","\n","  y_lined_up_with_x = np.asarray(y_lined_up_with_x)\n","\n","  y_values = deExtrapolateYs(x_time, y_time, y_lined_up_with_x)\n","  \n","  y_values.tofile(f'/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Data/Trenton_testing_prediction_accuracy/subject_{session.subject_number:03d}_{session.session_number:02d}__y.csv', sep='\\n')\n","  #y_lined_up_with_x.tofile(f'/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Caleb Playing with It/NonDesampled/subject_{session.subject_number:03d}_{session.session_number:02d}__y.csv', sep='\\n')\n","\n","  # print out accuracy and f1score \n","  total_accuracy, total_f1score, accuracy_per_class, guessed_vs_real_ratio = get_session_accuracy_and_f1_score(session, y_lined_up_with_x) # USING Y_LINED_UP_WITH_X\n","  print(\"Subject: \", session.subject_number, \" Session: \", session.session_number)\n","  print(\"Total Accuracy: \", total_accuracy)\n","  print(\"Total F1Score!: \", total_f1score)\n","  print(\"Accuracy Per Class: \", accuracy_per_class)\n","  print(\"Guessed/Real: \", guessed_vs_real_ratio, \" Ideal = 1, Overguessed > 1, Underguessed < 1\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"id":"apfpGUe38FSe","executionInfo":{"status":"error","timestamp":1649790724035,"user_tz":240,"elapsed":3299,"user":{"displayName":"Nathan Kohen","userId":"04529003586658249277"}},"outputId":"05cfdc86-ff0b-4654-89f6-9eb3a7f72eb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Models/nathan_messing_around_recangle_kernel_2.pt\n","Done processing session!\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-e99420231c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_sessions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mx_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetYLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is 1.5 for bad 77% model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-9b9b8ab6feb8>\u001b[0m in \u001b[0;36mgetYLabels\u001b[0;34m(session, image_width, model)\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_target\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0moutput_numpy\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_numpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-2529085d068f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m# x = x.view(-1, 128 * 30 * 6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m31\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (60 x 6). Kernel size: (6 x 30). Kernel size can't be greater than actual input size"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"QPqg4UW3hnwo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"moNktNLQhn_Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["session_y_value = get_Y_vlaues_from_session(session)"],"metadata":{"id":"DcZ_NxMHcaJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(y_values.shape)\n","print(session_y_value.shape)"],"metadata":{"id":"RW0OFCl1eImw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"hxwbSXDGeKnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(accuracy)"],"metadata":{"id":"4HVo1NcHeyD0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" from sklearn.metrics import precision_recall_fscore_support \n"," \n"," temp_precision_all, temp_recall_all, temp_fscore_all, _ = precision_recall_fscore_support(session_y_value, y_values, average=\"macro\", labels=classes, zero_division=0, beta=1) "],"metadata":{"id":"gyYNF2BLfBGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(temp_fscore_all)"],"metadata":{"id":"Ntuy-h7tfrMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_accuracy, total_f1score = get_session_accuracy_and_f1_score(session, y_values)\n","print(\"Total Accuracy: \", total_accuracy)\n","print(\"Total F1Score:  \", total_f1score)"],"metadata":{"id":"EKrnVlb2gXdO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"H502jNUGhjiO"},"execution_count":null,"outputs":[]}]}