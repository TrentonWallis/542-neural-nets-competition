{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Caleb Playing With Competition Results C1.2 Monday Afternoon.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"J-_wQPlIxomJ","executionInfo":{"status":"ok","timestamp":1648486255457,"user_tz":240,"elapsed":6635,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}}},"outputs":[],"source":["\n","# necessary imports\n","import numpy as np\n","import csv\n","import os\n","from google.colab import drive \n","import matplotlib.pyplot as plt\n","import random # Added by Caleb\n","import math # Added by Caleb\n","import os\n","import torch\n","import pandas as pd\n","from torchvision.io import read_image\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n"]},{"cell_type":"code","source":["from google.colab import drive \n","drive.mount('/content/drive/') ## mount to drive. This will ask for permission to access your Google drive each time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3c_WuMrOzN7T","executionInfo":{"status":"ok","timestamp":1648486260028,"user_tz":240,"elapsed":2777,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}},"outputId":"fd45f47a-1dd4-48f8-e3d4-f4809bc91221"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["data_folder_path = \"/content/drive/Shareddrives/Neural Nets/Competition/ECE542_sp2022_Project_TerrainRecognition/\" # path into Lobton's directory \n","type_of_data = \"TestData\" # Read in the type of data you want. Options are either:  'TrainingData' or 'TestData'\n","list_of_files = os.listdir(data_folder_path + type_of_data) # List everything in the directory at place 2022_Project_TerrainRecognition/TrainingData or /TestData (from line above)\n","list_of_files.sort() # Sort the list of files\n","print(list_of_files) # Print out the list of files\n","# need to load all this data in for augmentation (only the x data, but need to match what y data it connects with)\n","# we need to figure out what data we want to use too. "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJJ9EhzAzOQU","executionInfo":{"status":"ok","timestamp":1648486264451,"user_tz":240,"elapsed":1008,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}},"outputId":"c25d3769-f53a-442b-f423-a8f1431a59c6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['subject_009_01__x.csv', 'subject_009_01__x_time.csv', 'subject_009_01__y_time.csv', 'subject_010_01__x.csv', 'subject_010_01__x_time.csv', 'subject_010_01__y_time.csv', 'subject_011_01__x.csv', 'subject_011_01__x_time.csv', 'subject_011_01__y_time.csv', 'subject_012_01__x.csv', 'subject_012_01__x_time.csv', 'subject_012_01__y_time.csv']\n"]}]},{"cell_type":"code","source":["class CustomImageDataset(Dataset):\n","    def __init__(self, x_data, y_data, img_dir=None, transform=None, target_transform=None):\n","        self.img_labels = y_data\n","        self.img_dir = img_dir\n","        self.x_data = x_data\n","        self.y_data = y_data\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        image = self.x_data[idx]\n","        label = self.y_data[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label\n"],"metadata":{"id":"uZjKtqu5Vv-4","executionInfo":{"status":"ok","timestamp":1648486271924,"user_tz":240,"elapsed":430,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Code block created by Caleb\n","# Goal: Session class that holds subject and session number, and also returns the data for that session\n","\n","# This class can return the name of the file that holds the requested data\n","    # Example of how to use:\n","    # newSession = Session(4, 5)\n","    # newStr = newSession.xTimeName()\n","    # print(newStr)\n","    # # Prints out \"subject_004_05__x.csv\"\n","\n","class Session:\n","  def __init__(self, subject_number, session_number):\n","    self.subject_number = subject_number  # Initialize subject number\n","    self.session_number = session_number  # Initialize session number\n","\n","  # Each of the following member functions return the name of the specified file for that subject and session number of the Session:\n","\n","  def xTimeName(self):\n","    return \"subject_00\" + str(self.subject_number) + \"_0\" + str(self.session_number) + \"__x_time.csv\"\n","\n","  def yTimeName(self):\n","    return \"subject_00\" + str(self.subject_number) + \"_0\" + str(self.session_number) + \"__y_time.csv\"\n","\n","  def xDataName(self):\n","    return \"subject_00\" + str(self.subject_number) + \"_0\" + str(self.session_number) + \"__x.csv\"\n","\n","  def yDataName(self):\n","    return \"subject_00\" + str(self.subject_number) + \"_0\" + str(self.session_number) + \"__y.csv\"\n","\n","\n","  # This function input is the Session object that contians the subject and session numbers\n","  def getXDataFromFile(self):\n","    x_data_path = data_folder_path + \"TestData/\" + self.xDataName() # Get the path to the x_data file \n","    x_data = np.genfromtxt(x_data_path, delimiter=',')  # Read the data in from the text file\n","    return x_data  # Return the data array\n","    # This function returns the array of all the six x values\n","\n","  def getXTimeFromFile(self):\n","    x_time_path = data_folder_path + \"TestData/\" + self.xTimeName() # Get the path to the x_data file \n","    x_time = np.genfromtxt(x_time_path, delimiter=',')  # Read the data in from the text file\n","    return x_time  # Return the data array\n","    # This function returns the array of just the x time values\n","\n","  def getYTimeFromFile(self):\n","    y_time_path = data_folder_path + \"TestData/\" + self.yTimeName() # Get the path to the x_data file \n","    y_time = np.genfromtxt(y_time_path, delimiter=',')  # Read the data in from the text file\n","    return y_time  # Return the data array\n","    # This function returns the array of just the y time values\n","\n","\n"],"metadata":{"id":"9rupYvJ8zg7D","executionInfo":{"status":"ok","timestamp":1648486275068,"user_tz":240,"elapsed":390,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Code block created by Caleb:\n","# Goal is to create list of each session, with a unique session id (session id made up of subject number and session number)\n","\n","list_of_sessions = []\n","\n","for file_name in list_of_files:\n","  # Extract subject and session number from file_name:\n","  new_subject_number = int(file_name[8:11]) # Since all provided subject and session numbers are single digit, we can \n","  new_session_number = int(file_name[12:14]) #   pick them out of the file name by grabbing an exact character number.\n","  \n","\n","\n","  # Check if I should add this session to the list of sessions\n","  should_add_session = True # Create a variable that by default should add the session\n","  for session in list_of_sessions: # Loop through the sessions in the list of sessions (list I may need to add it to)\n","    comp_subject_number = session.subject_number # Get both new session and subject number\n","    comp_session_number = session.session_number #   save them as comp_\n","    if (comp_session_number == new_session_number) and (comp_subject_number == new_subject_number): # If comp session and subject are equal to new subject and session\n","      should_add_session = False # In this case, that would mean that I should /not/ add the new session\n","\n","  if should_add_session: # If I should add the session\n","    newSession = Session(new_subject_number, new_session_number) # Initialize the new session object with the new subject and session values\n","    list_of_sessions.append(newSession) # Append the new session to the list of sessions\n","\n","# Now list_of_sessions has a list of Session objects for each of the sessions\n","\n","# Print out the list of the sessions in list_of_sessions:\n","# for session in list_of_sessions:\n","#   newStr = \"Subject: \" + str(session.subject_number) + \". Session: \" + str(session.session_number)\n","#   print(newStr) \n"],"metadata":{"id":"0nsD3egZzhsK","executionInfo":{"status":"ok","timestamp":1648486278685,"user_tz":240,"elapsed":723,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Code block created by Caleb\n","# Goal: Create a function that will take in an array of size [(length of file) x 6] and pad it with zeros for image size\n","\n","# This function pads with image width - 1 rows of zeros\n","def padData(data, image_width):\n","  dim = [image_width - 1,6] # The dimensions of the zeros will be the width of the image and six wide\n","  zeroArray = np.zeros(dim) # Create an array with zeros at the beginning of the correct size\n","  return np.concatenate((zeroArray, data)) # Concatonate the two arrays together with the zeros at the beginning\n","\n","# Print out the data for a small data array to see where the zeros go\n","data = np.array([[1, 2, 3, 4, 5, 6], [3, 4, 5, 6, 7, 5]])\n","paddedData = padData(data, 3) \n","print(data)\n"],"metadata":{"id":"KUAJ9FFgy2le","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648486283013,"user_tz":240,"elapsed":575,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}},"outputId":"3de79079-76c2-4665-f242-9d877834b3dc"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2 3 4 5 6]\n"," [3 4 5 6 7 5]]\n"]}]},{"cell_type":"code","source":["# Code block created by Caleb\n","# Goal: Step three of the whiteboard photo, so create \"images\" from padded data\n","\n","# This function takes in the padded data (an array  [(image_width + 40*session lenght).x 6] ) and an integer of the width of an image\n","def createImages(paddedData, image_width):\n","  all_images = [] # Create an empty array that will eventually hold all the images for this session's data\n","  number_of_images = paddedData.shape[0] - image_width + 1  # The number of images I should create is padded_data - (image_width - 1)\n","  for i in range(number_of_images): # Loop through i for each of the images I need to create\n","    all_images.append(paddedData[i:(i+image_width)])  # Grab out the array from the padded data equal to the image_width and starting at i, and append it to all images\n","  return np.asarray(all_images) \n","\n","\n","# This example uses the 'data' array from the code block above to pass into this function to see if it successfully creates two images\n","#   One should have two rows of zeros (because it gets all the padding) and the next should have one row of zeros\n","images = createImages(paddedData, 3)\n","print(images)"],"metadata":{"id":"TD-14JARy7g1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648486285491,"user_tz":240,"elapsed":439,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}},"outputId":"babfd5e2-c616-4061-d3ca-4341c1d79fc5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0.]\n","  [1. 2. 3. 4. 5. 6.]]\n","\n"," [[0. 0. 0. 0. 0. 0.]\n","  [1. 2. 3. 4. 5. 6.]\n","  [3. 4. 5. 6. 7. 5.]]]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"HIglJIso0iTR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# I will use the first session for this example:\n","example_session = list_of_sessions[0]\n","\n","example_x_data = example_session.getXDataFromFile()\n","example_x_time = example_session.getXTimeFromFile()\n","#example_y_data = example_session.getYDataFromFile() # y data does not exist here\n","example_y_time = example_session.getYTimeFromFile()\n","\n","# No need to extrapolate the ys \n","#xample_extrapolated_y = extrapolatedYs(example_x_time, example_y_time, example_y_data)\n","\n","# Now the x data and the extrapolate_y have the correct sizes, so y is the predictions we want\n","print(\"New y size, and then x data shape\")\n","\n","print(example_x_data.shape)\n","print(\"- - -\")\n","\n","# Now I will show the examples of transforming the x values into images. \n","example_image_width = 60 # You can play around with the width of the image\n","example_x_padded = padData(example_x_data, example_image_width)\n","print(\"With padding:\")\n","print(example_x_padded.shape)\n","print(\"- - -\")\n","\n","example_x_images = createImages(example_x_padded, example_image_width)\n","print(\"Shape of images, so should be back down to number of x values, with image_size x 6 secondary dimensions\")\n","print(example_x_images.shape)\n","print(\"- - -\")\n","print(\"Printing first images\")\n","# print(example_x_images[0])\n","# print(example_x_images[1])\n","\n","# So the data we're treating just like images for classification are:\n","# example_x_images          as the images\n","# example_extrapolated_y    as the labels"],"metadata":{"id":"_PUNpbVOz7TI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648486289191,"user_tz":240,"elapsed":994,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}},"outputId":"92955972-6fb7-4520-f8f1-ebefe95a3416"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["New y size, and then x data shape\n","(37991, 6)\n","- - -\n","With padding:\n","(38050, 6)\n","- - -\n","Shape of images, so should be back down to number of x values, with image_size x 6 secondary dimensions\n","(37991, 60, 6)\n","- - -\n","Printing first images\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"jSf_V3gL0fys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code block created by Trenton and Caleb\n","\n","def getImagesFromSession(session, image_width):\n","  image_width_number = int(image_width * 40) # This is the conversion rate between image_width in seconds and image_width the number of samples in an image\n","\n","  x_data = session.getXDataFromFile() # Get all the data for that session\n","  x_time = session.getXTimeFromFile()\n","  y_time = session.getYTimeFromFile()\n","\n","  \n","  x_padded = padData(x_data, image_width_number) # Pad the x values\n","  x_images = createImages(x_padded, image_width_number) # Then create images\n","\n","\n","\n","  print(\"Done processing session!\")\n","\n","\n","  return np.array(x_time), np.asarray(x_images), np.asarray(y_time)\n","\n","#Yt_train = Yt_train.type(torch.LongTensor)\n","# This next line calls the function to get the data for the model with the parameters passed in.\n","# Remember that image width and set length are in seconds\n","\n"],"metadata":{"id":"yLtJnh3O0OSr","executionInfo":{"status":"ok","timestamp":1648486294241,"user_tz":240,"elapsed":1558,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["our_transform = transforms.Compose([\n","    # Converting RGB [0,255] to Tensor [0,1]\n","    transforms.ToTensor(),\n","    ])\n","\n","def getYLabels(session, image_width, model):\n","  x_time, x_images, y_time = getImagesFromSession(session, image_width)\n","  y_lined_up_with_x_predictions = []\n","\n","  model.eval()\n","\n","  # This version would iterate over all:\n","  # for image in x_images:\n","  #   row = Variable(Tensor([image]).float())\n","\n","  #   yhat = model(row)\n","  #   yhat = yhat.detach().numpy()\n","\n","  #   y_lined_up_with_x_predictions.append(yhat)\n","\n","\n","\n","\n","\n","\n","\n","  \n","  return x_time, x_images, y_time, y_lined_up_with_x_predictions\n","\n","\n","  "],"metadata":{"id":"T4fLQZcaQV1a","executionInfo":{"status":"ok","timestamp":1648486977237,"user_tz":240,"elapsed":521,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def loadModelStateFromFile(model, filename):\n","  ''' Load model's state onto model passed in from a model file'''\n","  competition_path = \"/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Models/\" #path to data folder in drive\n","  model_file_path = os.path.join(competition_path, filename+\".pt\")  #joing path and adding .npy to filename passed in\n","  print(model_file_path)\n","  model.load_state_dict(torch.load(model_file_path)) # Should not need a return since the model will be modified through its object \n"],"metadata":{"id":"QDV-y2u_S_9o","executionInfo":{"status":"ok","timestamp":1648487147949,"user_tz":240,"elapsed":455,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Custom CNN\n","# Defining the CNN architecture\n","class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.conv1 = nn.Conv2d(1, 6, 5, padding=2, padding_mode='zeros', dtype=float)\n","   ## nn.MaxPool2d()\n","    self.conv2 = nn.Conv2d(6, 16, 5, dtype=float)\n","    self.fc1 = nn.Linear(16 * 56 * 2, 800, dtype=float)\n","    self.fc2 = nn.Linear(800, 200, dtype=float) \n","    self.fc3 = nn.Linear(200, 50, dtype=float)\n","    self.fc4 = nn.Linear(50, 4, dtype=float)\n","  def forward(self, x):\n","    x = F.relu(self.conv1(x))\n","    x = F.relu(self.conv2(x))\n","    x = x.view(-1, 16 * 56 * 2) # At this point the feature map is 5 x 5 x 16\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    x = F.relu(self.fc3(x))\n","    x = self.fc4(x)\n","    return x"],"metadata":{"id":"Ay5vxZP3S0G-","executionInfo":{"status":"ok","timestamp":1648487151695,"user_tz":240,"elapsed":451,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["test_session = list_of_sessions[0]\n","test_model = Net()\n","\n","loadModelStateFromFile(test_model, \"Test_Model\")\n","test_x_time, test_x_data, test_y_time, test_predictions = getYLabels(test_session, 60, test_model)\n"],"metadata":{"id":"HTlguJmNSLRj","colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1648487155602,"user_tz":240,"elapsed":2330,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}},"outputId":"ad2d4f45-212e-4fcc-ab32-181e3818f479"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Models/Test_Model.pt\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-3d68ed57bb20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloadModelStateFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Test_Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_x_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetYLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-974453ebfa9c>\u001b[0m in \u001b[0;36mgetYLabels\u001b[0;34m(session, image_width, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetYLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mx_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetImagesFromSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-a6ec6084facd>\u001b[0m in \u001b[0;36mgetImagesFromSession\u001b[0;34m(session, image_width)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mx_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width_number\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pad the x values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mx_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width_number\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Then create images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-c797b11218cd>\u001b[0m in \u001b[0;36mcreateImages\u001b[0;34m(paddedData, image_width)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Loop through i for each of the images I need to create\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mall_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Grab out the array from the padded data equal to the image_width and starting at i, and append it to all images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Horrible code just playing around. Please ignore\n","\n","import torch\n","from torch import Tensor\n","\n","\n","test_model = Net()\n","\n","loadModelStateFromFile(test_model, \"Test_Model\")\n","\n","test_model.eval()\n","\n","newSession = Session(9, 1)\n","\n","x_time, x_images, y_time = getImagesFromSession(newSession, 1) # Pass in 1 second to then get 40 images\n","y_lined_up_with_x_predictions = []\n","\n","print(x_images.shape)\n","\n","image = x_images[0]\n","print(image.shape)\n","\n","row = Tensor([x_images[0]]).float()\n","\n","print()\n","\n","yhat = test_model(row)\n","yhat = yhat.detach().numpy()\n","\n","print(yhat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"COrLJeaffg66","executionInfo":{"status":"error","timestamp":1648488040191,"user_tz":240,"elapsed":940,"user":{"displayName":"Caleb Wheeler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02287818206377120960"}},"outputId":"569c8eb1-685a-4760-92fa-33d08602ce0b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Models/Test_Model.pt\n","Done processing session!\n","(37991, 40, 6)\n","(40, 6)\n","\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-c8a91bd86639>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-208ae0c37c09>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m56\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# At this point the feature map is 5 x 5 x 16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [6, 1, 5, 5], but got 3-dimensional input of size [1, 40, 6] instead"]}]},{"cell_type":"code","source":["# \"Downsample\" Y labels to correpond to what needs to be submitted\n","def deExtrapolateYs(x_time, y_time, y_lined_up_with_x):\n","  correctY = [] #Empty list for the newly transformed y values\n","  x_time_array = np.asarray(x_time)\n","  for y_t in y_time: # Loop over every y_time value\n","    index = (np.abs(x_time_array - y_t)).argmin() # Get index of closeset x_time to the y_t you are currently looking for\n","    correctY.append(y_lined_up_with_x[index]) # Add the y value at that index to the transformed y's\n","  return np.asarray(correctY)\n"],"metadata":{"id":"F_YFV96NT5K7"},"execution_count":null,"outputs":[]}]}