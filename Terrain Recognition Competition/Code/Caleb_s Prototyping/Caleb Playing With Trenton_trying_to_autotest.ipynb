{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Caleb Playing With Trenton_trying_to_autotest.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"J-_wQPlIxomJ"},"outputs":[],"source":["\n","# necessary imports\n","import numpy as np\n","import csv\n","import os\n","from google.colab import drive \n","import matplotlib.pyplot as plt\n","import random # Added by Caleb\n","import math # Added by Caleb\n","import os\n","import torch\n","import pandas as pd\n","from torchvision.io import read_image\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n"]},{"cell_type":"code","source":["from google.colab import drive \n","drive.mount('/content/drive/') ## mount to drive. This will ask for permission to access your Google drive each time"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3c_WuMrOzN7T","executionInfo":{"status":"ok","timestamp":1651024243819,"user_tz":240,"elapsed":1629,"user":{"displayName":"Trenton Wallis","userId":"12490720454166063115"}},"outputId":"0324eb53-a9ac-497f-9571-cb2371b665a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["data_folder_path = \"/content/drive/Shareddrives/Neural Nets/Competition/ECE542_sp2022_Project_TerrainRecognition/\" # path into Lobton's directory \n","type_of_data = \"TestData\" # Read in the type of data you want. Options are either:  'TrainingData' or 'TestData'\n","TRAINING = True\n","list_of_files = os.listdir(data_folder_path + type_of_data) # List everything in the directory at place 2022_Project_TerrainRecognition/TrainingData or /TestData (from line above)\n","list_of_files.sort() # Sort the list of files\n","print(list_of_files) # Print out the list of files\n","# need to load all this data in for augmentation (only the x data, but need to match what y data it connects with)\n","# we need to figure out what data we want to use too. "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJJ9EhzAzOQU","executionInfo":{"status":"ok","timestamp":1651024243821,"user_tz":240,"elapsed":18,"user":{"displayName":"Trenton Wallis","userId":"12490720454166063115"}},"outputId":"81ad388d-25a6-4c9f-94b9-491d43c4ebc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['subject_009_01__x.csv', 'subject_009_01__x_time.csv', 'subject_009_01__y_time.csv', 'subject_010_01__x.csv', 'subject_010_01__x_time.csv', 'subject_010_01__y_time.csv', 'subject_011_01__x.csv', 'subject_011_01__x_time.csv', 'subject_011_01__y_time.csv', 'subject_012_01__x.csv', 'subject_012_01__x_time.csv', 'subject_012_01__y_time.csv']\n"]}]},{"cell_type":"code","source":["class CustomImageDataset(Dataset):\n","    def __init__(self, x_data, y_data, img_dir=None, transform=None, target_transform=None):\n","        self.img_labels = y_data\n","        self.img_dir = img_dir\n","        self.x_data = x_data\n","        self.y_data = y_data\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        image = self.x_data[idx]\n","        label = self.y_data[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        return image, label\n"],"metadata":{"id":"uZjKtqu5Vv-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title\n","# Code block created by Caleb\n","# Goal: Session class that holds subject and session number, and also returns the data for that session\n","\n","# This class can return the name of the file that holds the requested data\n","    # Example of how to use:\n","    # newSession = Session(4, 5)\n","    # newStr = newSession.xTimeName()\n","    # print(newStr)\n","    # # Prints out \"subject_004_05__x.csv\"\n","\n","class Session:\n","  def __init__(self, subject_number, session_number):\n","    self.subject_number = int(subject_number)  # Initialize subject number\n","    self.session_number = int(session_number)  # Initialize session number\n","\n","  # Each of the following member functions return the name of the specified file for that subject and session number of the Session:\n","\n","  def xTimeName(self):\n","    return \"subject_\" + f\"{self.subject_number:03d}\" + \"_\" + f\"{self.session_number:02d}\" + \"__x_time.csv\"\n","\n","  def yTimeName(self):\n","    return \"subject_\" + f\"{self.subject_number:03d}\" + \"_\" + f\"{self.session_number:02d}\" + \"__y_time.csv\"\n","\n","  def xDataName(self):\n","    return \"subject_\" + f\"{self.subject_number:03d}\" + \"_\" + f\"{self.session_number:02d}\" + \"__x.csv\"\n","\n","  def yDataName(self):\n","    return \"subject_\" + f\"{self.subject_number:03d}\" + \"_\" + f\"{self.session_number:02d}\" + \"__y.csv\"\n","\n","\n","  # This function input is the Session object that contians the subject and session numbers\n","  def getXDataFromFile(self):\n","    x_data_path = data_folder_path + \"TestData/\" + self.xDataName() # Get the path to the x_data file \n","    x_data = np.genfromtxt(x_data_path, delimiter=',')  # Read the data in from the text file\n","    return x_data  # Return the data array\n","    # This function returns the array of all the six x values\n","\n","  def getXTimeFromFile(self):\n","    x_time_path = data_folder_path + \"TestData/\" + self.xTimeName() # Get the path to the x_data file \n","    x_time = np.genfromtxt(x_time_path, delimiter=',')  # Read the data in from the text file\n","    return x_time  # Return the data array\n","    # This function returns the array of just the x time values\n","\n","  def getYTimeFromFile(self):\n","    y_time_path = data_folder_path + \"TestData/\" + self.yTimeName() # Get the path to the x_data file \n","    y_time = np.genfromtxt(y_time_path, delimiter=',')  # Read the data in from the text file\n","    return y_time  # Return the data array\n","    # This function returns the array of just the y time values\n","\n","\n"],"metadata":{"id":"9rupYvJ8zg7D","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code block created by Caleb:\n","# Goal is to create list of each session, with a unique session id (session id made up of subject number and session number)\n","\n","list_of_sessions = []\n","\n","for file_name in list_of_files:\n","  # Extract subject and session number from file_name:\n","  new_subject_number = int(file_name[8:11]) # Since all provided subject and session numbers are single digit, we can \n","  new_session_number = int(file_name[12:14]) #   pick them out of the file name by grabbing an exact character number.\n","  \n","\n","\n","  # Check if I should add this session to the list of sessions\n","  should_add_session = True # Create a variable that by default should add the session\n","  for session in list_of_sessions: # Loop through the sessions in the list of sessions (list I may need to add it to)\n","    comp_subject_number = session.subject_number # Get both new session and subject number\n","    comp_session_number = session.session_number #   save them as comp_\n","    if (comp_session_number == new_session_number) and (comp_subject_number == new_subject_number): # If comp session and subject are equal to new subject and session\n","      should_add_session = False # In this case, that would mean that I should /not/ add the new session\n","\n","  if should_add_session: # If I should add the session\n","    newSession = Session(new_subject_number, new_session_number) # Initialize the new session object with the new subject and session values\n","    list_of_sessions.append(newSession) # Append the new session to the list of sessions\n","  break\n","# Now list_of_sessions has a list of Session objects for each of the sessions\n","\n","# Print out the list of the sessions in list_of_sessions:\n","# for session in list_of_sessions:\n","#   newStr = \"Subject: \" + str(session.subject_number) + \". Session: \" + str(session.session_number)\n","#   print(newStr) \n"],"metadata":{"id":"0nsD3egZzhsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code block created by Caleb\n","# Goal: Create a function that will take in an array of size [(length of file) x 6] and pad it with zeros for image size\n","\n","# This function pads with image width - 1 rows of zeros\n","def padData(data, image_width):\n","  dim = [image_width - 1,6] # The dimensions of the zeros will be the width of the image and six wide\n","  zeroArray = np.zeros(dim) # Create an array with zeros at the beginning of the correct size\n","  return np.concatenate((zeroArray, data)) # Concatonate the two arrays together with the zeros at the beginning\n","\n","# Print out the data for a small data array to see where the zeros go\n","data = np.array([[1, 2, 3, 4, 5, 6], [3, 4, 5, 6, 7, 5]])\n","paddedData = padData(data, 3) \n","print(data)"],"metadata":{"id":"KUAJ9FFgy2le","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651024243823,"user_tz":240,"elapsed":16,"user":{"displayName":"Trenton Wallis","userId":"12490720454166063115"}},"outputId":"108d2189-0268-4b44-e2b0-5c94199a6da4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2 3 4 5 6]\n"," [3 4 5 6 7 5]]\n"]}]},{"cell_type":"code","source":["# Code block created by Caleb\n","# Goal: Step three of the whiteboard photo, so create \"images\" from padded data\n","\n","# This function takes in the padded data (an array  [(image_width + 40*session lenght).x 6] ) and an integer of the width of an image\n","def createImages(paddedData, image_width):\n","  all_images = [] # Create an empty array that will eventually hold all the images for this session's data\n","  number_of_images = paddedData.shape[0] - image_width + 1  # The number of images I should create is padded_data - (image_width - 1)\n","  for i in range(number_of_images): # Loop through i for each of the images I need to create\n","    all_images.append(paddedData[i:(i+image_width)])  # Grab out the array from the padded data equal to the image_width and starting at i, and append it to all images\n","  return np.asarray(all_images) \n","\n","\n","# This example uses the 'data' array from the code block above to pass into this function to see if it successfully creates two images\n","#   One should have two rows of zeros (because it gets all the padding) and the next should have one row of zeros\n","images = createImages(paddedData, 3)\n","print(images)"],"metadata":{"id":"TD-14JARy7g1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651024243823,"user_tz":240,"elapsed":14,"user":{"displayName":"Trenton Wallis","userId":"12490720454166063115"}},"outputId":"c301ba18-5c9d-4abe-b8cc-f3ec9c63227c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0.]\n","  [1. 2. 3. 4. 5. 6.]]\n","\n"," [[0. 0. 0. 0. 0. 0.]\n","  [1. 2. 3. 4. 5. 6.]\n","  [3. 4. 5. 6. 7. 5.]]]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"HIglJIso0iTR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# I will use the first session for this example:\n","example_session = list_of_sessions[0]\n","\n","example_x_data = example_session.getXDataFromFile()\n","example_x_time = example_session.getXTimeFromFile()\n","#example_y_data = example_session.getYDataFromFile() # y data does not exist here\n","example_y_time = example_session.getYTimeFromFile()\n","\n","# No need to extrapolate the ys \n","#xample_extrapolated_y = extrapolatedYs(example_x_time, example_y_time, example_y_data)\n","\n","# Now the x data and the extrapolate_y have the correct sizes, so y is the predictions we want\n","print(\"New y size, and then x data shape\")\n","\n","print(example_x_data.shape)\n","print(\"- - -\")\n","\n","# Now I will show the examples of transforming the x values into images. \n","example_image_width = 60 # You can play around with the width of the image\n","example_x_padded = padData(example_x_data, example_image_width)\n","print(\"With padding:\")\n","print(example_x_padded.shape)\n","print(\"- - -\")\n","\n","example_x_images = createImages(example_x_padded, example_image_width)\n","print(\"Shape of images, so should be back down to number of x values, with image_size x 6 secondary dimensions\")\n","print(example_x_images.shape)\n","print(\"- - -\")\n","print(\"Printing first images\")\n","# print(example_x_images[0])\n","# print(example_x_images[1])\n","\n","# So the data we're treating just like images for classification are:\n","# example_x_images          as the images\n","# example_extrapolated_y    as the labels"],"metadata":{"id":"_PUNpbVOz7TI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651024244519,"user_tz":240,"elapsed":707,"user":{"displayName":"Trenton Wallis","userId":"12490720454166063115"}},"outputId":"1cdaebfd-9237-42c3-ca0a-c88d236de751"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["New y size, and then x data shape\n","(37991, 6)\n","- - -\n","With padding:\n","(38050, 6)\n","- - -\n","Shape of images, so should be back down to number of x values, with image_size x 6 secondary dimensions\n","(37991, 60, 6)\n","- - -\n","Printing first images\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"jSf_V3gL0fys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Code block created by Caleb\n","\n","def getImagesFromSession(session, image_width):\n","  image_width_number = int(image_width * 40) # This is the conversion rate between image_width in seconds and image_width the number of samples in an image\n","\n","  x_data = session.getXDataFromFile() # Get all the data for that session\n","  x_time = session.getXTimeFromFile()\n","  y_time = session.getYTimeFromFile()\n","\n","  \n","  x_padded = padData(x_data, image_width_number) # Pad the x values\n","  x_images = createImages(x_padded, image_width_number) # Then create images\n","\n","\n","\n","  print(\"Done processing session!\")\n","\n","\n","  return np.array(x_time), np.asarray(x_images), np.asarray(y_time)\n","\n","#Yt_train = Yt_train.type(torch.LongTensor)\n","# This next line calls the function to get the data for the model with the parameters passed in.\n","# Remember that image width and set length are in seconds\n","\n"],"metadata":{"id":"yLtJnh3O0OSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["our_transform = transforms.Compose([\n","    # Converting RGB [0,255] to Tensor [0,1]\n","    transforms.ToTensor(),\n","    ])\n","\n","# def getYLabels(session, image_width, model):\n","#   x_time, x_images, y_time = getImagesFromSession(session, image_width)\n","#   model.eval()\n","#   test_data = CustomImageDataset(x_images, x_time, transform=our_transform) # x_time is just filler here \n","#   test_loader = torch.utils.data.DataLoader(test_data, batch_size=len(x_images))\n","#   _iter = iter(test_loader)\n","#   print(type(_iter))\n","#   data, index = next(_iter)\n","#   print(data.shape)\n","#   print(type(data))\n","#   predictions = model(data)\n","#   return x_time, x_images, y_time, predictions\n","\n","\n","\n","\n","\n","def getYLabels(session, image_width, model): #TODO: Could there be a bug here? So our model is good but we arent spitting things out in the righ place?????\n","  x_time, x_images, y_time = getImagesFromSession(session, image_width)\n","  #print(\"X_Images Shape:\", x_images.shape)\n","  predictions = []\n","\n","  model.eval()\n","  test_data = CustomImageDataset(x_images, x_time, transform=our_transform) # x_time is just filler here \n","  test_loader = torch.utils.data.DataLoader(test_data, batch_size=20)\n","  for data, _target in test_loader:\n","  \n","    output = model(data)\n","    output_numpy =  output.detach().numpy()\n","    for out in output_numpy:\n","      predictions.append(out)\n","\n","  return x_time, x_images, y_time, np.asarray(predictions)\n","\n","\n","  "],"metadata":{"id":"T4fLQZcaQV1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def loadModelStateFromFile(model, filename):\n","  ''' Load model's state onto model passed in from a model file'''\n","  competition_path = \"/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Models/\" #path to data folder in drive\n","  model_file_path = os.path.join(competition_path, filename+\".pt\")  #joing path and adding .npy to filename passed in\n","  print(model_file_path)\n","  model.load_state_dict(torch.load(model_file_path, map_location=torch.device('cpu'))) # Should not need a return since the model will be modified through its object \n"],"metadata":{"id":"QDV-y2u_S_9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Custom CNN\n","# Defining the CNN architecture\n","#Trenton's Net class\n","# class Net(nn.Module):\n","#   def __init__(self):\n","#     super(Net, self).__init__()\n","#     self.conv1 = nn.Conv2d(1, 6, 5, padding=2, padding_mode='zeros', dtype=float)\n","#    ## nn.MaxPool2d()\n","#     self.conv2 = nn.Conv2d(6, 16, 5, dtype=float)\n","#     self.fc1 = nn.Linear(16 * 56 * 2, 800, dtype=float)\n","#     self.fc2 = nn.Linear(800, 200, dtype=float) \n","#     self.fc3 = nn.Linear(200, 50, dtype=float)\n","#     self.fc4 = nn.Linear(50, 4, dtype=float)\n","#   def forward(self, x):\n","#     x = F.relu(self.conv1(x))\n","#     x = F.relu(self.conv2(x))\n","#     x = x.view(-1, 16 * 56 * 2) # At this point the feature map is 5 x 5 x 16\n","#     x = F.relu(self.fc1(x))\n","#     x = F.relu(self.fc2(x))\n","#     x = F.relu(self.fc3(x))\n","#     x = self.fc4(x)\n","#     return x\n","# class Net(nn.Module):\n","#   def __init__(self):\n","#     super(Net, self).__init__()\n","#     self.conv1 = nn.Conv2d(1, 6, 5, padding=2, padding_mode='zeros', dtype=float)\n","#    ## nn.MaxPool2d()\n","#     self.conv2 = nn.Conv2d(6, 16, 5, dtype=float)\n","#     self.fc1 = nn.Linear(16 * 36 * 2, 800, dtype=float)\n","#     self.fc2 = nn.Linear(800, 200, dtype=float) \n","#     self.fc3 = nn.Linear(200, 50, dtype=float)\n","#     self.fc4 = nn.Linear(50, 4, dtype=float)\n","#   def forward(self, x):\n","#     x = F.relu(self.conv1(x))\n","#     x = F.relu(self.conv2(x))\n","#     x = x.view(-1, 16 * 36 * 2) # At this point the feature map is 5 x 5 x 16\n","#     x = F.relu(self.fc1(x))\n","#     x = F.relu(self.fc2(x))\n","#     x = F.relu(self.fc3(x))\n","#     x = self.fc4(x)\n","#     return x\n","\n","# class Net(nn.Module):\n","#   def __init__(self, ):\n","#     super(Net, self).__init__()\n","#     self.conv1 = nn.Conv2d(1, 4, 5, padding=2, padding_mode='zeros', dtype=float)\n","#    ## nn.MaxPool2d()\n","#     self.conv2 = nn.Conv2d(4, 8, 5, padding=2, padding_mode='zeros', dtype=float)\n","#     self.drop2 = nn.Dropout2d(0.1)\n","#     self.drop1 = nn.Dropout(0.1)\n","#     self.batchNorm1 = nn.BatchNorm2d(4, dtype = float)\n","#     self.batchNorm2 = nn.BatchNorm2d(8, dtype = float)\n","#     self.batchNorm3 = nn.BatchNorm1d(512, dtype = float)\n","#     self.batchNorm4 = nn.BatchNorm1d(128, dtype = float)\n","#     self.batchNorm5 = nn.BatchNorm1d(32, dtype = float)\n","#     self.fc1 = nn.Linear(8 * 40 * 6, 512, dtype=float)\n","#     self.fc2 = nn.Linear(512, 128, dtype=float) \n","#     self.fc3 = nn.Linear(128, 32, dtype=float)\n","#     self.fc4 = nn.Linear(32, 4, dtype=float)\n","#   def forward(self, x):\n","#     x = self.drop2(F.relu(self.batchNorm1(self.conv1(x))))\n","#     x = self.drop2(F.relu(self.batchNorm2(self.conv2(x))))\n","#     x = x.view(-1, 8 * 40 * 6) # At this point the feature map is 5 x 5 x 16\n","#     x = self.drop1(F.relu(self.batchNorm3(self.fc1(x))))\n","#     x = self.drop1(F.relu(self.batchNorm4(self.fc2(x))))\n","#     x = self.drop1(F.relu(self.batchNorm5(self.fc3(x))))\n","#     x = self.fc4(x)\n","#     return x\n","\n","# Nathan/Caleb's Randomization Working Net:\n","# Defining the CNN architecture\n","# class Net(nn.Module):\n","#   def __init__(self, ):\n","#     super(Net, self).__init__()\n","#     self.conv1 = nn.Conv2d(1, 6, 5, padding=2, padding_mode='zeros', dtype=float)\n","#    ## nn.MaxPool2d()\n","#     self.conv2 = nn.Conv2d(6, 16, 5, padding=2, padding_mode='zeros', dtype=float)\n","#     self.drop2 = nn.Dropout2d(0.1)\n","#     self.drop1 = nn.Dropout(0.1)\n","#     self.batchNorm1 = nn.BatchNorm2d(6, dtype = float)\n","#     self.batchNorm2 = nn.BatchNorm2d(16, dtype = float)\n","#     self.batchNorm3 = nn.BatchNorm1d(800, dtype = float)\n","#     self.batchNorm4 = nn.BatchNorm1d(200, dtype = float)\n","#     self.batchNorm5 = nn.BatchNorm1d(50, dtype = float)\n","#     self.fc1 = nn.Linear(16 * 60 * 6, 800, dtype=float)\n","#     self.fc2 = nn.Linear(800, 200, dtype=float) \n","#     self.fc3 = nn.Linear(200, 50, dtype=float)\n","#     self.fc4 = nn.Linear(50, 4, dtype=float)\n","#   def forward(self, x):\n","#     x = self.drop2(F.relu(self.batchNorm1(self.conv1(x))))\n","#     x = self.drop2(F.relu(self.batchNorm2(self.conv2(x))))\n","#     x = x.view(-1, 16 * 60 * 6) # At this point the feature map is 5 x 5 x 16\n","#     x = self.drop1(F.relu(self.batchNorm3(self.fc1(x))))\n","#     x = self.drop1(F.relu(self.batchNorm4(self.fc2(x))))\n","#     x = self.drop1(F.relu(self.batchNorm5(self.fc3(x))))\n","#     x = self.fc4(x)\n","#     return x\n","\n","\n","# Nathan's 90+% model\n","class Net(nn.Module):\n","  def __init__(self, ):\n","    super(Net, self).__init__()\n","    self.conv1 = nn.Conv2d(1, 128, (30,6), dtype=float)\n","    self.drop2 = nn.Dropout2d(0.5)\n","    self.drop1 = nn.Dropout(0.2)\n","    self.maxPool = nn.MaxPool1d(1, 31)\n","    # self.batchNorm1 = nn.BatchNorm2d(128, dtype = float)\n","    # self.batchNorm2 = nn.BatchNorm2d(16, dtype = float)\n","    # self.batchNorm3 = nn.BatchNorm1d(800, dtype = float)\n","    # self.batchNorm4 = nn.BatchNorm1d(200, dtype = float)\n","    # self.batchNorm5 = nn.BatchNorm1d(50, dtype = float)\n","    self.fc1 = nn.Linear(128 * 31 * 1, 128, dtype=float)\n","    self.fc2 = nn.Linear(128, 64, dtype=float) \n","    self.fc3 = nn.Linear(64, 32, dtype=float)\n","    self.fc4 = nn.Linear(32, 4, dtype=float)\n","  def forward(self, x):\n","    x = self.drop2(F.relu(self.conv1(x)))\n","    # x = x.view(-1, 128 * 30 * 6) \n","    x = x.view(-1, 128 * 31 * 1) \n","    # x= self.maxPool(x)\n","    x = self.drop1(F.relu(self.fc1(x)))\n","    x = self.drop1(F.relu(self.fc2(x)))\n","    x = F.relu(self.fc3(x))\n","    x = self.fc4(x)\n","    return x\n","\n"],"metadata":{"id":"Ay5vxZP3S0G-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_session = list_of_sessions[0]\n","# test_model = Net()\n","\n","# loadModelStateFromFile(test_model, \"Test_Model\")\n","# test_x_time, test_x_data, test_y_time, test_predictions = getYLabels(test_session, 1.5, test_model)\n"],"metadata":{"id":"HTlguJmNSLRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(test_predictions)\n","\n","# print(test_predictions[0])\n","\n","\n","# print(test_predictions[100][0])\n","# print(test_predictions[100][1])\n","# print(test_predictions[100][2])\n","# print(test_predictions[100][3])\n"],"metadata":{"id":"oJfSb-07k02L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# # for test_pred in test_predictions:\n","# #   print(test_pred.shape)\n","# _, max_indexes = torch.max(test_predictions, 1)\n","# #max_indexes.append(max_index)\n","\n","\n","\n","\n"],"metadata":{"id":"1mKIVf3X1H0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(max_indexes[1000])\n","\n","# # for index in max_indexes:\n","# #   print(int(index))\n","# y_lined_up_with_x = []\n","# for index in max_indexes:\n","#   y_lined_up_with_x.append(int(index))\n","\n","# y_lined_up_with_x = np.asarray(y_lined_up_with_x)"],"metadata":{"id":"xT4qRwWf2gaJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \"Downsample\" Y labels to correpond to what needs to be submitted\n","def deExtrapolateYs(x_time, y_time, y_lined_up_with_x):\n","  correctY = [] #Empty list for the newly transformed y values\n","  x_time_array = np.asarray(x_time)\n","  for y_t in y_time: # Loop over every y_time value\n","    index = (np.abs(x_time_array - y_t)).argmin() # Get index of closeset x_time to the y_t you are currently looking for\n","    correctY.append(y_lined_up_with_x[index]) # Add the y value at that index to the transformed y's\n","  return np.asarray(correctY)\n"],"metadata":{"id":"F_YFV96NT5K7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# actual_ys = deExtrapolateYs(test_x_time, test_y_time, y_lined_up_with_x)"],"metadata":{"id":"19X5WI0i3AQo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(actual_ys.shape)"],"metadata":{"id":"25P0HUBq3fs5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(actual_ys[0])"],"metadata":{"id":"wxsdfQp03rjl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pd.DataFrame(actual_ys).to_csv('first_y_perhaps')"],"metadata":{"id":"965soREA3yOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# np.savetxt('/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Caleb Playing with It/first_y_save_txt', actual_ys)"],"metadata":{"id":"N48xa_vj4Z1U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pd.DataFrame(actual_ys).to_csv('/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Caleb Playing with It/first_y_maybe')"],"metadata":{"id":"yHTuxMwn5sEs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# actual_ys.tofile('/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Caleb Playing with It/first_y_maybe', sep='\\n')"],"metadata":{"id":"Ij7MCl5R5v1o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_Y_values_from_session(session):\n","  # basicaly just getting data as numpy array \n","  # need to make sure y_session data even exits, may be on session without data\n","  y_data_path = data_folder_path + \"TrainingData/\" + \"subject_\" + f\"{session.subject_number:03d}\" + \"_\" + f\"{session.session_number:02d}\" + \"__y.csv\" # Get the path to the x_data file \n","  try:  \n","    y_data = np.genfromtxt(y_data_path, delimiter=',')  # Read the data in from the text file\n","  except:\n","    print(y_data_path, \" was NOT FOUND\")\n","    return None # returns none so we cna exit\n","  return y_data  # Return the data array\n","  "],"metadata":{"id":"ElP6S4VzcR1h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extrapolatedYs(x_time, y_time, y):\n","  transformedY = [] #Empty list for the newly transformed y values\n","  y_time_array = np.asarray(y_time) # Create the y_time values as an array\n","  for x_t in x_time: # Loop over every x_time value\n","    index = (np.abs(y_time_array - x_t)).argmin() # I found this online to get the index of the closest value from the y_time arrays\n","    transformedY.append(y[index]) # Add the y value at that index to the transformed y's\n","  return np.asarray(transformedY)"],"metadata":{"id":"73BXQaIqTaXR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" from sklearn.metrics import precision_recall_fscore_support \n"," classes = [0, 1, 2, 3]\n","\n","def get_session_accuracy_and_f1_score(indv_session, predcitions_y_values):\n","  session_true_y_values = get_Y_values_from_session(indv_session)\n","  session_upsampled_y_values = extrapolatedYs(session.getXTimeFromFile(), session.getYTimeFromFile(),  session_true_y_values)\n","  temp_precision_all, temp_recall_all, temp_fscore_all, _ = precision_recall_fscore_support(session_upsampled_y_values, predcitions_y_values, average=\"macro\", labels=classes, zero_division=0, beta=1) \n","  amount_correct = np.sum(predcitions_y_values == session_upsampled_y_values)\n","\n","  # get amount of each number \n","  amount_per_class = [0, 0, 0, 0]\n","  amount_guessed_correct_per_class = [0, 0, 0, 0]\n","  amount_guessed_per_class = [0, 0, 0 ,0]\n","  accuracy_per_class = [0, 0, 0, 0]\n","  guessed_vs_real_ratio = [0, 0, 0, 0]\n","  \n","  for index, true_value in enumerate(session_upsampled_y_values):\n","    amount_per_class[int(true_value)] +=1\n","    if(true_value == predcitions_y_values[index]):\n","      amount_guessed_correct_per_class[int(true_value)] += 1\n","  \n","  for label in classes:\n","    if amount_per_class[label] == 0:\n","        amount_per_class[label] = .000001\n","    accuracy_per_class[label] = amount_guessed_correct_per_class[label]/amount_per_class[label] # getting accuracy \n","    amount_guessed_per_class[label] = np.sum(predcitions_y_values == label)\n","    guessed_vs_real_ratio[label] = amount_guessed_per_class[label]/ amount_per_class[label]\n","\n","\n","\n","  accuracy = amount_correct/session_upsampled_y_values.shape[0]\n","  return accuracy, temp_fscore_all, accuracy_per_class, guessed_vs_real_ratio\n","\n","\n","def get_session_accuracy_and_f1_score_undextrapolated(indv_session, predcitions_y_values):\n","  session_true_y_values = get_Y_values_from_session(indv_session)\n","  # session_upsampled_y_values = extrapolatedYs(session.getXTimeFromFile(), session.getYTimeFromFile(),  session_true_y_values)\n","  temp_precision_all, temp_recall_all, temp_fscore_all, _ = precision_recall_fscore_support(session_true_y_values, predcitions_y_values, average=\"macro\", labels=classes, zero_division=0, beta=1) \n","  amount_correct = np.sum(predcitions_y_values == session_true_y_values)\n","\n","  # get amount of each number \n","  amount_per_class = [0, 0, 0, 0]\n","  amount_guessed_correct_per_class = [0, 0, 0, 0]\n","  amount_guessed_per_class = [0, 0, 0 ,0]\n","  accuracy_per_class = [0, 0, 0, 0]\n","  guessed_vs_real_ratio = [0, 0, 0, 0]\n","  \n","  for index, true_value in enumerate(session_true_y_values):\n","    amount_per_class[int(true_value)] +=1\n","    if(true_value == predcitions_y_values[index]):\n","      amount_guessed_correct_per_class[int(true_value)] += 1\n","  \n","  for label in classes:\n","    if amount_per_class[label] == 0:\n","        amount_per_class[label] = .000001\n","    accuracy_per_class[label] = amount_guessed_correct_per_class[label]/amount_per_class[label] # getting accuracy \n","    amount_guessed_per_class[label] = np.sum(predcitions_y_values == label)\n","    guessed_vs_real_ratio[label] = amount_guessed_per_class[label]/ amount_per_class[label]\n","\n","\n","\n","  accuracy = amount_correct/session_true_y_values.shape[0]\n","  return accuracy, temp_fscore_all, accuracy_per_class, guessed_vs_real_ratio\n","\n"],"metadata":{"id":"hk5EmRaLfspO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"uAMSzfO9S2k7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Net()\n","loadModelStateFromFile(model, \"report_model\") # \"Test_Model\" for bad 77% model\n","\n","one_session = []\n","#one_session.append(list_of_sessions[1])\n","\n","for session in list_of_sessions:\n","  x_time, x_data, y_time, predictions = getYLabels(session, 1.5, model) # This is 1.5 for bad 77% model\n","  predictions = torch.from_numpy(predictions)\n","  _, max_indexes = torch.max(predictions, 1)\n","\n","  y_lined_up_with_x = []\n","  for index in max_indexes:\n","    y_lined_up_with_x.append(int(index))\n","\n","  y_lined_up_with_x = np.asarray(y_lined_up_with_x)\n","\n","  y_values = deExtrapolateYs(x_time, y_time, y_lined_up_with_x)\n","  \n","  y_values.tofile(f'/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Data/Best_Submission/subject_{session.subject_number:03d}_{session.session_number:02d}__y.csv', sep='\\n')\n","  #y_lined_up_with_x.tofile(f'/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Caleb Playing with It/NonDesampled/subject_{session.subject_number:03d}_{session.session_number:02d}__y.csv', sep='\\n')\n","\n","  # print out accuracy and f1score\n","  if TRAINING:  \n","    if False:\n","      total_accuracy, total_f1score, accuracy_per_class, guessed_vs_real_ratio = get_session_accuracy_and_f1_score(session, y_lined_up_with_x) # USING Y_LINED_UP_WITH_X\n","    else:\n","      total_accuracy, total_f1score, accuracy_per_class, guessed_vs_real_ratio = get_session_accuracy_and_f1_score_undextrapolated(session, y_values)\n","    print(\"Subject: \", session.subject_number, \" Session: \", session.session_number)\n","    print(\"Total Accuracy: \", total_accuracy)\n","    print(\"Total F1Score!: \", total_f1score)\n","    print(\"Accuracy Per Class: \", accuracy_per_class)\n","    print(\"Guessed/Real: \", guessed_vs_real_ratio, \" Ideal = 1, Overguessed > 1, Underguessed < 1\")\n","\n","  else:\n","    pass\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":798},"id":"apfpGUe38FSe","executionInfo":{"status":"error","timestamp":1651024965172,"user_tz":240,"elapsed":10918,"user":{"displayName":"Trenton Wallis","userId":"12490720454166063115"}},"outputId":"00f5921b-06e0-41c4-bd53-16fc74950127"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/Neural Nets/Competition/Phase 1/Code/Models/report_model.pt\n","Done processing session!\n","/content/drive/Shareddrives/Neural Nets/Competition/ECE542_sp2022_Project_TerrainRecognition/TrainingData/subject_009_01__y.csv  was NOT FOUND\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-ef0936118f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mTRAINING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mtotal_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_f1score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_per_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguessed_vs_real_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session_accuracy_and_f1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lined_up_with_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# USING Y_LINED_UP_WITH_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mtotal_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_f1score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_per_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguessed_vs_real_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session_accuracy_and_f1_score_undextrapolated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-59-742cf5f6aa85>\u001b[0m in \u001b[0;36mget_session_accuracy_and_f1_score\u001b[0;34m(indv_session, predcitions_y_values)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_session_accuracy_and_f1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindv_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredcitions_y_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0msession_true_y_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_Y_values_from_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindv_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m  \u001b[0msession_upsampled_y_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextrapolatedYs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetXTimeFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetYTimeFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msession_true_y_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m  \u001b[0mtemp_precision_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_recall_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_fscore_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_upsampled_y_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredcitions_y_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m  \u001b[0mamount_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredcitions_y_values\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msession_upsampled_y_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-58-9161ca4efa58>\u001b[0m in \u001b[0;36mextrapolatedYs\u001b[0;34m(x_time, y_time, y)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_time\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Loop over every x_time value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_time_array\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# I found this online to get the index of the closest value from the y_time arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtransformedY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Add the y value at that index to the transformed y's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformedY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"QPqg4UW3hnwo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"moNktNLQhn_Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["session_y_value = get_Y_vlaues_from_session(session)"],"metadata":{"id":"DcZ_NxMHcaJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(y_values.shape)\n","print(session_y_value.shape)"],"metadata":{"id":"RW0OFCl1eImw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"hxwbSXDGeKnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(accuracy)"],"metadata":{"id":"4HVo1NcHeyD0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" from sklearn.metrics import precision_recall_fscore_support \n"," \n"," temp_precision_all, temp_recall_all, temp_fscore_all, _ = precision_recall_fscore_support(session_y_value, y_values, average=\"macro\", labels=classes, zero_division=0, beta=1) "],"metadata":{"id":"gyYNF2BLfBGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(temp_fscore_all)"],"metadata":{"id":"Ntuy-h7tfrMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_accuracy, total_f1score = get_session_accuracy_and_f1_score(session, y_values)\n","print(\"Total Accuracy: \", total_accuracy)\n","print(\"Total F1Score:  \", total_f1score)"],"metadata":{"id":"EKrnVlb2gXdO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"H502jNUGhjiO"},"execution_count":null,"outputs":[]}]}